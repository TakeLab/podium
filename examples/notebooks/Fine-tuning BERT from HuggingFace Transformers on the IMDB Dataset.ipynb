{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning BERT from HuggingFace Transformers on the IMDB Dataset\n",
    ">Note: In this tutorial we use a smaller version of BERT, called __DistilBert__, that is easier and faster to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "from podium.datasets import IMDB, Iterator\n",
    "from podium.models import Experiment\n",
    "from podium.models.impl.pytorch import TorchTrainer, TorchModel\n",
    "from podium.pipeline import Pipeline\n",
    "from podium.storage import Field, LabelField, Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the fields\n",
    "\n",
    "* text - applies `BertTokenizer` to the instance data. We don't store `attention_mask` to reduce the memory footprint of the dataset, instead we create it ourselves on the fly.\n",
    "* label - stores binary labels that represent the sentiment of an instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fields():\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "    \n",
    "    def text_to_tokens(string):\n",
    "        input_ids = tokenizer(string,\n",
    "                              max_length=128,\n",
    "                              padding=False,\n",
    "                              truncation=True,\n",
    "                              return_attention_mask=False\n",
    "                             )['input_ids']\n",
    "        \n",
    "        return tokenizer.convert_ids_to_tokens(input_ids)        \n",
    "        \n",
    "    def token_to_input_id(token):\n",
    "        return tokenizer.convert_tokens_to_ids(token)\n",
    "        \n",
    "    text = Field(name='text',\n",
    "                 tokenizer=text_to_tokens,\n",
    "                 custom_numericalize=token_to_input_id,\n",
    "                 padding_token=0)\n",
    "    \n",
    "    label = LabelField(name='label', vocab=Vocab(specials=()))\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'label': label\n",
    "    } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping the model\n",
    "`DistilBertForSequenceClassification` is a standard PyTorch `Module`so it can be easily wrapped in another `Module` that has a proper interface to Podium - the model has to return a dictionary that has a key `pred` that points to the model predictions. As mentioned earlier, we are creating the attention mask ourselves so this is a good place to do it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModelWrapper(nn.Module):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', \n",
    "                                                                         return_dict=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        attention_mask = (x != 0).long()\n",
    "        return_dict = self.model(x, attention_mask)\n",
    "        return_dict['pred'] = return_dict['logits']\n",
    "        return return_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = create_fields()\n",
    "imdb_train, imdb_test = IMDB.get_dataset_splits(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the loaded data \n",
    "\n",
    "> Note: `None` values in the oupput are for caching purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, ['[CLS]', 'bro', '##m', '##well', 'high', 'is', 'a', 'cartoon', 'comedy', '.', 'it', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life', ',', 'such', 'as', '\"', 'teachers', '\"', '.', 'my', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'bro', '##m', '##well', 'high', \"'\", 's', 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', '\"', 'teachers', '\"', '.', 'the', 'scramble', 'to', 'survive', 'financially', ',', 'the', 'insight', '##ful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', 'teachers', \"'\", 'po', '##mp', ',', 'the', 'pet', '##tine', '##ss', 'of', 'the', 'whole', 'situation', ',', 'all', 'remind', 'me', 'of', 'the', 'schools', 'i', 'knew', 'and', 'their', 'students', '.', 'when', 'i', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school', ',', 'i', 'immediately', 'recalled', '.', '.', '.', '.', '[SEP]'])\n",
      "('positive', None)\n"
     ]
    }
   ],
   "source": [
    "print(imdb_train[0].text)\n",
    "print(imdb_train[0].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Podium Experiment\n",
    "\n",
    "To fine-tune our model, we define an `Experiment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    'lr': 1e-5,\n",
    "    'clip': float('inf'), # disable gradient clipping\n",
    "    'num_epochs': 3,\n",
    "}\n",
    "model_config['num_classes'] = len(fields['label'].vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch]: 781 in 2.44000 seconds, loss=0.404058\n",
      "Total time for train epoch: 5957.261180639267\n",
      "[Valid]: 781 in 0.62000 seconds, loss=0.08201\n",
      "Total time for valid epoch: 1807.9500014781952\n",
      "[Batch]: 781 in 4.37339 seconds, loss=0.124552\n",
      "Total time for train epoch: 7614.580070734024\n",
      "[Valid]: 781 in 1.03415 seconds, loss=0.09244\n",
      "Total time for valid epoch: 2411.316132545471\n",
      "[Batch]: 781 in 2.63686 seconds, loss=0.112098\n",
      "Total time for train epoch: 8038.268185377121\n",
      "[Valid]: 781 in 0.83022 seconds, loss=0.06469\n",
      "Total time for valid epoch: 2486.869591474533\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "iterator = Iterator(batch_size=32)\n",
    "trainer = TorchTrainer(model_config['num_epochs'], device, iterator, imdb_test)\n",
    "\n",
    "# here we have to swap axes to nullify the effect of swapping axes afterwards\n",
    "# because we work with the batch-first model (we should add this option to Podium!!!)\n",
    "feature_transformer = lambda feature_batch: feature_batch[0].astype(np.int64).swapaxes(0, 1)\n",
    "label_transformer = lambda label_batch: label_batch[0].astype(np.int64)\n",
    "\n",
    "experiment = Experiment(TorchModel, \n",
    "                        trainer=trainer, \n",
    "                        feature_transformer=feature_transformer,\n",
    "                        label_transform_fn=label_transformer)\n",
    "\n",
    "experiment.fit(imdb_train,  \n",
    "               model_kwargs={\n",
    "                   'model_class': BertModelWrapper,  \n",
    "                   'criterion': nn.CrossEntropyLoss(),  \n",
    "                   'optimizer': optim.AdamW,\n",
    "                   'device': device,\n",
    "                   **model_config\n",
    "               })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading the fitted model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities for saving/loading the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, file_path):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(fitted_model, f)\n",
    "\n",
    "def load_model(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_model = experiment.model\n",
    "\n",
    "model_file = 'bert_model.pt'\n",
    "save_model(fitted_model, model_file)\n",
    "loaded_model = load_model(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing and making predictions on raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilities for making predictions with the raw model on the parsed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_to_torch_transformer = lambda t: torch.from_numpy(t[0].astype(np.int64)).to(device)\n",
    "\n",
    "def make_predictions(raw_model, dataset):\n",
    "    raw_model.eval()\n",
    "    \n",
    "    # here we call `.batch()` on the dataset to get numericalized examples\n",
    "    X, _ = dataset.batch()\n",
    "    with torch.no_grad():\n",
    "        predictions = raw_model(cast_to_torch_transformer(X))['pred']\n",
    "        return predictions.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`raw_model` is an instance of `BertModelWrapper`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.90126  , -1.9712397],\n",
       "       [ 0.9901674, -1.2427605],\n",
       "       [ 2.4357972, -2.7238822],\n",
       "       [ 2.5466118, -2.854033 ]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_model = loaded_model.model\n",
    "predictions = make_predictions(raw_model, imdb_test[:4])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the predictions are valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred == y_true: True\n"
     ]
    }
   ],
   "source": [
    "_, y = imdb_test[:4].batch()\n",
    "y_pred = predictions.argmax(axis=1)\n",
    "print('y_pred == y_true:', (y_pred == y[0].ravel()).all())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions on raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "instance: ['This movie is horrible'], predicted label: negative, predictions: [-2.3370621  2.6273308]\n",
      "instance: ['This movie is great!'], predicted label: positive, predictions: [ 2.3128583 -2.7027676]\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline(fields=list(fields.values()), \n",
    "                example_format='list',\n",
    "                feature_transformer=cast_to_torch_transformer,\n",
    "                model=loaded_model)\n",
    "\n",
    "instances = [\n",
    "    ['This movie is horrible'],\n",
    "    ['This movie is great!']\n",
    "]\n",
    "\n",
    "for instance in instances:\n",
    "    predictions = pipe.predict_raw(instance)\n",
    "    print(f'instance: {instance}, predicted label: '\n",
    "          f'{fields[\"label\"].vocab.itos[predictions.argmax()]}, '\n",
    "          f'predictions: {predictions}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "podium-env",
   "language": "python",
   "name": "podium-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
