{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import takepod\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from takepod.datasets import Iterator, BasicSupervisedImdbDataset\n",
    "from takepod.storage import LabelField, Field, Vocab\n",
    "from takepod.storage.vectorizers.impl import GloVe\n",
    "from takepod.models import Experiment\n",
    "from takepod.pipeline import Pipeline\n",
    "\n",
    "from takepod.models.impl.pytorch import TorchTrainer, TorchModel, AttentionRNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading & preprocessing\n",
    "\n",
    "When using `podium` you have three options for data loading:\n",
    "1. Use one of our built-in datasets\n",
    "2. Use a flexible data loader from a predefined format (`TabularDataset` loads from `.csv`, `.tsv` files)\n",
    "3. Write your own data loader for a dataset in a custom format\n",
    "\n",
    "### IMDB sentiment classification\n",
    "\n",
    "![Imdb logo](img/imdb_logo_small.png)\n",
    "\n",
    "For this walkthough, we will use the [IMDB sentiment classification dataset](https://ai.stanford.edu/~amaas/data/sentiment/). This dataset is built-in, so let's check what exactly does that mean.\n",
    "\n",
    "- Each built-in dataset has a static method `get_dataset_splits` which downloads and caches the splits for that model and returns them as a tuple (train, valid?, test).\n",
    "  - Note: the IMDB dataset only has a train and test split\n",
    "- We will first load the IMDB dataset with default `Fields` (preprocessing pipelines) and check whether we might want to modify something.\n",
    "- You can inspect the default fields by calling the `get_default_fields` static method of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train, imdb_test = BasicSupervisedImdbDataset.get_dataset_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data in a single dataset instance:\n",
      "==================================================\n",
      "(None, ['i', 'am', 'and', 'was', 'very', 'entertained', 'by', 'the', 'movie', '.', 'it', 'was', 'my', 'all', 'time', 'favorite', 'movie', 'of', '1976', '.', 'being', 'raised', 'in', 'the', '70', \"'s\", ',', 'i', 'was', 'so', 'in', 'love', 'with', 'kris', 'kristoffersons', 'look', 'and', 'demeanor', ',', 'of', 'course', 'i', 'am', 'no', 'movie', 'critic', ',', 'but', 'for', 'the', 'time', 'era', ',', 'i', 'think', 'it', 'was', 'very', 'good', '.', 'i', 'very', 'much', 'like', 'the', 'combo', 'of', 'streisand', 'and', 'kristofferson', '.', 'i', 'thought', 'they', 'worked', 'very', 'well', 'together', '.', 'i', 'have', 'seen', 'the', 'movie', 'many', 'times', 'and', 'still', 'love', 'the', 'two', 'of', 'them', 'as', 'esther', 'and', 'john', 'norman', '.', 'i', 'am', 'a', 'very', 'huge', 'fan', 'of', 'kris', 'and', 'see', 'him', 'in', 'concert', 'when', 'i', 'can', '.', 'what', 'a', 'talented', 'singer', 'song', 'writer', ',', 'not', 'to', 'mention', ',', 'actor', '.', 'i', 'have', 'seen', 'him', 'in', 'many', 'movies', ',', 'but', 'still', 'think', 'back', 'to', 'a', 'star', 'is', 'born', '.'])\n",
      "('positive', None)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "first_instance = imdb_train[0]\n",
    "text, label = first_instance.text, first_instance.label\n",
    "\n",
    "\n",
    "# Note that the text is cased\n",
    "print(\"Data in a single dataset instance:\")\n",
    "print(\"=\"*50)\n",
    "print(text)\n",
    "print(label)\n",
    "print(\"=\"*50)\n",
    "\n",
    "def get_text_statistics(dataset):\n",
    "    instance_lengths = [len(ex.text[1]) for ex in dataset]\n",
    "    print(f\"Input text length interval [{min(instance_lengths)}, {max(instance_lengths)}] \\n\" \n",
    "                             f\"Average length {np.mean(instance_lengths)} +- {np.std(instance_lengths)}\")\n",
    "get_text_statistics(imdb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using hooks during data preprocessing\n",
    "The average length of instances in the dataset is large, while the longest instance has 2789 tokens. \n",
    "Instances of this length are likely to cause memory issues when batched and transferred to GPU, so we would like to limit this. We might also want only lowercase data in our instances.\n",
    "\n",
    "We can implement this ourselves easily by adding `hooks` to our model. Hooks are methods with a standardized signature which view and modify the data flowing through the preprocessing pipeline at **two** points.\n",
    "1. **Pre-tokenization hooks**:\n",
    "  - pre-tokenization hooks work on raw data (the loaded input string). You might want to lowercase data during pre-tokenization, but keep in mind that most tokenizers (such as `spacy`) are sensitive to casing and might produce bad results. Since we use `spacy` as the `IMDB` tokenizer, this is not a good choice and we might want to delegate lowercasing to post-tokenization.\n",
    "2. **Post-tokenization hooks**:\n",
    "  - post-tokenization hooks work on raw **and** tokenized data. Here you might want to limit the length of your instances to a fixed amount or filter out stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The signature of post-tokenization hooks has *two* arguments: raw and tokenized data\n",
    "\n",
    "def lowercase(raw, tokenized):\n",
    "    \"\"\"Applies lowercasing as a post-tokenization hook\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Raw : str\n",
    "        the untokenized input data\n",
    "    Tokenized: list(str)\n",
    "        list of tokens.\n",
    "    Returns\n",
    "    -------\n",
    "    Raw: str \n",
    "        unmodified input\n",
    "    Tokenized: list(str) \n",
    "        lowercased tokenized data\n",
    "    \"\"\"\n",
    "    return raw, [token.lower() for token in tokenized]\n",
    "\n",
    "def max_length(raw, data, length=200):\n",
    "    \"\"\"Applies lowercasing as a post-tokenization hook\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Raw : str\n",
    "        the untokenized input data\n",
    "    Tokenized: list(str)\n",
    "        list of tokens.\n",
    "    Length: int\n",
    "        maximum length for each instance \n",
    "    Returns\n",
    "    -------\n",
    "    Raw: str \n",
    "        unmodified input\n",
    "    Tokenized: list(str) \n",
    "        tokenized data truncated to `length`\n",
    "    \"\"\"\n",
    "    return raw, data[:length]\n",
    "\n",
    "\n",
    "def create_fields():\n",
    "    # Define the vocabulary\n",
    "    max_vocab_size = 10000\n",
    "    min_frequency = 5\n",
    "    vocab = Vocab(max_size=max_vocab_size, min_freq=min_frequency)\n",
    "\n",
    "    text = Field(name='text', vocab=vocab, tokenizer='spacy', store_as_raw=False)\n",
    "    # Add preprpocessing hooks to model\n",
    "    # 1. Lowercase\n",
    "    text.add_posttokenize_hook(lowercase)\n",
    "    # 2. Truncate to length\n",
    "    text.add_posttokenize_hook(max_length)\n",
    "\n",
    "    label = LabelField(name='label', vocab = Vocab(specials=()))\n",
    "    return {text.name : text, label.name: label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = create_fields()\n",
    "# TODO: remove Dataset, Basic, Supervised from IMDB name\n",
    "imdb_train, imdb_test = BasicSupervisedImdbDataset.get_dataset_splits(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text length interval [11, 200] \n",
      "Average length 170.3254 +- 41.14426515129417\n"
     ]
    }
   ],
   "source": [
    "get_text_statistics(imdb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained embeddings for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
      " [ 0.04656    0.21318   -0.0074364 ...  0.0090611 -0.20989    0.053913 ]\n",
      " ...\n",
      " [-0.24734    0.019346   0.13974   ...  0.34035    0.0824     0.38554  ]\n",
      " [ 0.67287   -0.43249    0.1106    ... -0.16644    0.21169    0.45995  ]\n",
      " [ 0.034368   0.22004    0.14626   ... -0.18641   -0.032439   0.24544  ]]\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe embeddings\n",
    "vocab = fields['text'].vocab\n",
    "embeddings = GloVe().load_vocab(vocab)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define & train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-specific configuration\n",
    "model_config = {\n",
    "    'rnn_type': 'LSTM',\n",
    "    'embed_dim': 300,\n",
    "    'hidden_dim': 150,\n",
    "    'nlayers': 1,\n",
    "    'lr': 1e-3,\n",
    "    'clip': 5,\n",
    "    'epochs': 1,\n",
    "    'batch_size': 32,\n",
    "    'dropout': 0.,\n",
    "    'bidirectional': True,\n",
    "    'gpu': -1\n",
    "}\n",
    "\n",
    "# Task-specific configuration\n",
    "model_config['vocab_size'] = len(vocab)\n",
    "label_vocab = fields['label'].vocab\n",
    "model_config['num_classes'] = len(label_vocab)\n",
    "model_config['pretrained_embedding'] = embeddings\n",
    "\n",
    "device = torch.device('cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameter size: 3543002\n",
      "[Batch]: 781 in 0.34126 seconds, loss=0.57051\n",
      "Total time for train epoch: 464.8692126274109\n",
      "[Valid]: 781 in 0.05970 seconds, loss=0.66946\n",
      "Total time for valid epoch: 75.99735260009766\n"
     ]
    }
   ],
   "source": [
    "data_iterator = Iterator(batch_size=32)\n",
    "\n",
    "trainer = TorchTrainer(model_config['epochs'], device, data_iterator, imdb_test)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "experiment = Experiment(TorchModel, trainer=trainer)\n",
    "model = experiment.fit(\n",
    "    imdb_train,\n",
    "    model_kwargs={\n",
    "        'model_class': AttentionRNN, \n",
    "        'criterion': criterion,\n",
    "        'optimizer': torch.optim.Adam,\n",
    "        'device': device,\n",
    "        **model_config\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'model_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f442d36c4530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_save_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mload_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/takepod-0.0.1-py3.7.egg/takepod/models/impl/pytorch/models.py\u001b[0m in \u001b[0;36m__setstate__\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'device'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_config'"
     ]
    }
   ],
   "source": [
    "# Check serialization for _model_ only (should be for experiment as well)\n",
    "import pickle\n",
    "fitted_model = experiment.model\n",
    "\n",
    "model_save_file = 'model.pt'\n",
    "with open(model_save_file, 'wb') as dump_file:\n",
    "    pickle.dump(fitted_model, dump_file)\n",
    "\n",
    "with open(model_save_file, 'rb') as load_file:\n",
    "    loaded_model = pickle.load(load_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For instance: ['This movie is horrible'], the prediction is: 0, with logits: [-6.198414  6.626996]\n",
      "For instance: ['This movie is great!'], the prediction is: 1, with logits: [ 3.8818069 -3.9210994]\n"
     ]
    }
   ],
   "source": [
    "ft = experiment.feature_transformer\n",
    "cast_to_torch_transformer = lambda t: torch.from_numpy(ft.transform(t).swapaxes(0,1)).to(device)\n",
    "\n",
    "pipe = Pipeline(\n",
    "  fields = list(fields.values()),\n",
    "  example_format = 'list',\n",
    "  feature_transformer = cast_to_torch_transformer,\n",
    "  model = fitted_model\n",
    "  )\n",
    "\n",
    "instances = [\n",
    "        ['This movie is horrible'], \n",
    "        ['This movie is great!']\n",
    "]\n",
    "\n",
    "# Make IMDB labels \"positive\" and \"negative\"\n",
    "for instance in instances:\n",
    "    prediction = pipe.predict_raw(instance)\n",
    "    print(f\"For instance: {instance}, the prediction is: {fields['label'].vocab.itos[prediction.argmax()]}, with logits: {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
